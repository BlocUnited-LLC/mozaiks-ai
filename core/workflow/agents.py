# ==============================================================================
# FILE: core/workflow/agents.py  
# DESCRIPTION: Workflow-agnostic agent factory - loads from modular JSON configs
# ==============================================================================
import logging
import importlib.util  # retained only if future local dynamic imports are needed
import sys
import os
from pathlib import Path
from typing import Dict, List, Callable, Any

from core.observability.otel_helpers import timed_span
from autogen import ConversableAgent
from .workflow_manager import workflow_manager


logger = logging.getLogger(__name__)

async def define_agents(workflow_name: str):
    """
    Define agents with unified transport channel - fully workflow-agnostic.
    Loads agent configurations from modular JSON files.
    
    Args:
        workflow_name: Name of the workflow to load agents for
        
    Returns:
        Dictionary of agent instances
    """
    
    logger.info(f"üèóÔ∏è [AGENTS] Creating agents for workflow: {workflow_name}")
    from time import perf_counter
    start_time = perf_counter()

    # Load workflow configuration using file manager
    workflow_config = workflow_manager.get_config(workflow_name)
    
    if not workflow_config:
        logger.error(f"‚ùå [AGENTS] No configuration found for workflow: {workflow_name}")
        return {}
    
    agent_configs = workflow_config.get('agents', {})
    
    # Handle nested structure: agents -> agents -> agent_definitions
    if 'agents' in agent_configs:
        agent_configs = agent_configs['agents']
    
    logger.debug(f"üîß [AGENTS] Loading {len(agent_configs)} agent definitions")
    
    # ---------------------------------------------------------------
    # Load a single base LLM config; per-agent structured configs resolved by registry
    logger.debug("üîß [AGENTS] Loading base LLM config...")
    try:
        # Centralized llm_config (caching + provider aggregation)
        from .llm_config import get_llm_config as _get_base_llm_config
        _, base_llm_config = await _get_base_llm_config(stream=True)
    except Exception as e:
        logger.error(f"‚ùå [AGENTS] Failed to load base LLM config: {e}")
        return {}
    logger.debug("‚úÖ [AGENTS] Base LLM config loaded")
    
    # Tool function discovery via centralized loader (loads ALL tools including UI_Tools)
    try:
        from .agent_tools import load_agent_tool_functions
        agent_tool_functions = load_agent_tool_functions(workflow_name)
    except Exception as tool_load_err:
        logger.warning(f"üß© [AGENTS] Failed loading agent tool functions: {tool_load_err}")
        agent_tool_functions = {}

    agents: Dict[str, ConversableAgent] = {}

    # NOTE: UserProxyAgent is auto-generated by orchestration_patterns.py
    # based on workflow config human_in_the_loop flag. No need to create it here.
    
    # Create agents dynamically from JSON configuration
    for agent_name, agent_config in agent_configs.items():
        # Use centralized timed_span helper (adds mozaiks.* prefix and duration attr)
        with timed_span("agents.create", attributes={
            "workflow_name": workflow_name,
            "agent_name": agent_name,
        }):
            logger.debug(f"üîß [AGENTS] Creating agent '{agent_name}' dynamically from JSON config...")

            # Try to get structured model for this specific agent via registry
            try:
                from .structured_outputs import get_llm_for_workflow as _get_structured_llm
                _, llm_config = await _get_structured_llm(workflow_name, 'base', agent_name=agent_name)
                logger.debug(f"üîß [AGENTS] Got structured LLM config for {agent_name}: {llm_config}")
            except Exception as e:
                logger.debug(f"üîß [AGENTS] Failed to get structured config for {agent_name}, using base: {e}")
                llm_config = base_llm_config
                logger.debug(f"üîß [AGENTS] Using base LLM config for {agent_name}: {llm_config}")

            # Create the agent with configuration from JSON
            agent_functions = agent_tool_functions.get(agent_name, [])
            # Debug: inspect the functions we plan to attach so we can diagnose registration issues
            if agent_functions:
                func_details = []
                for i, fn in enumerate(agent_functions):
                    func_details.append({
                        "index": i,
                        "repr": repr(fn),
                        "callable": callable(fn),
                        "name": getattr(fn, "__name__", None),
                        "module": getattr(fn, "__module__", None),
                    })
                logger.debug(f"üß© [AGENTS] Attaching {len(agent_functions)} tool functions to {agent_name}: {func_details}")
            else:
                logger.debug(f"üß© [AGENTS] No tool functions found for {agent_name}")

            # Validate functions before passing to ConversableAgent
            for i, fn in enumerate(agent_functions):
                if not callable(fn):
                    logger.error(f"üß© [AGENTS] Tool function at index {i} for agent '{agent_name}' is not callable: {fn}")
            
            logger.debug(f"üîß [AGENTS] Final config for {agent_name}: config_list={llm_config.get('config_list', [])} other_keys={list(k for k in llm_config.keys() if k != 'config_list')}")
            
            # Additional debug - make a deep copy to see if something is modifying the original
            import copy
            config_copy = copy.deepcopy(llm_config)
            logger.debug(f"üîß [AGENTS] Config copy for {agent_name}: {config_copy}")
            
            # Check if config_list entries are valid IMMEDIATELY before creating agent
            config_list = llm_config.get('config_list', [])
            logger.debug(f"üîß [AGENTS] About to create agent {agent_name} with config_list length: {len(config_list)}")
            for i, entry in enumerate(config_list):
                logger.debug(f"üîß [AGENTS] FINAL CHECK Config entry [{i}] for {agent_name}: {entry}")
                if not isinstance(entry, dict):
                    logger.error(f"‚ùå [AGENTS] FATAL ERROR: Config entry [{i}] is not a dict: {type(entry)} {entry}")
                    raise ValueError(f"Config entry [{i}] is not a dict for agent {agent_name}")
                if not entry.get('model'):
                    logger.error(f"‚ùå [AGENTS] FATAL ERROR: Config entry [{i}] missing model field: {entry}")
                    raise ValueError(f"Config entry [{i}] missing model field for agent {agent_name}")
            
            logger.debug(f"üîß [AGENTS] Creating ConversableAgent {agent_name} with validated config...")
            
            # LAST CHANCE DEBUG - inspect the actual llm_config right before AG2 gets it
            logger.debug(f"üîß [AGENTS] ABSOLUTE FINAL CONFIG CHECK for {agent_name}:")
            logger.debug(f"üîß [AGENTS] llm_config type: {type(llm_config)}")
            logger.debug(f"üîß [AGENTS] llm_config keys: {list(llm_config.keys()) if isinstance(llm_config, dict) else 'NOT_DICT'}")
            
            final_config_list = llm_config.get('config_list', []) if isinstance(llm_config, dict) else []
            logger.debug(f"üîß [AGENTS] config_list length: {len(final_config_list)}")
            
            for idx, entry in enumerate(final_config_list):
                logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}]: {entry}")
                logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] type: {type(entry)}")
                if isinstance(entry, dict):
                    logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] keys: {list(entry.keys())}")
                    logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] has model: {'model' in entry}")
                    logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] model value: {entry.get('model', 'MISSING')}")
            
            try:
                agent = ConversableAgent(
                    name=agent_name,
                    system_message=agent_config.get('system_message', ''),
                    llm_config=llm_config,
                    human_input_mode=agent_config.get('human_input_mode', 'NEVER'),
                    max_consecutive_auto_reply=agent_config.get('max_consecutive_auto_reply', 2),
                    functions=agent_functions,  # AG2 accepts empty list
                )
                # After creation, log what the agent reports back (if accessible) about attached functions
                try:
                    attached = getattr(agent, 'functions', None)
                    if attached is None:
                        logger.debug(f"‚úÖ [AGENTS] ConversableAgent {agent_name} created (no 'functions' attribute exposed)")
                    else:
                        attached_summary = [{"name": getattr(f, '__name__', None), "callable": callable(f)} for f in attached]
                        logger.debug(f"‚úÖ [AGENTS] ConversableAgent {agent_name} created with functions: {attached_summary}")
                except Exception as _ex:
                    logger.debug(f"‚úÖ [AGENTS] ConversableAgent {agent_name} created but could not introspect 'functions': {_ex}")
            
            except Exception as e:
                logger.error(f"‚ùå [AGENTS] CRITICAL ERROR creating ConversableAgent {agent_name}: {e}")
                logger.error(f"‚ùå [AGENTS] FINAL CONFIG DUMP: {llm_config}")
                raise

            agents[agent_name] = agent

            # Minimal agent creation confirmation
            logger.debug(f"‚úÖ [AGENTS] Created '{agent_name}' with {len(agent_tool_functions.get(agent_name, []))} tools")

    # Completion log remains generic
    agent_count = len(agents)
    duration = perf_counter() - start_time
    logger.info(f"‚úÖ [AGENTS] Created {agent_count} agents for '{workflow_name}' in {duration:.2f}s")
    logger.debug(f"üîç [AGENTS] Agent names: {list(agents.keys())}")
    
    # Import and use consolidated logging for summary
    from logs.logging_config import get_workflow_session_logger
    workflow_logger = get_workflow_session_logger(workflow_name)
    
    # Log tool binding summary with proper parameters
    total_tools = sum(len(tools) for tools in agent_tool_functions.values())
    workflow_logger.log_tool_binding_summary("ALL_AGENTS", total_tools, list(agent_tool_functions.keys()))

    # NOTE: Tool registration is handled by the modular tool system
    logger.info("üîß [AGENTS] Tools registration handled by modular tool system")

    # ------------------------------------------------------------------
    # HOOK REGISTRATION
    # Register any hooks declared in workflows/<workflow>/hooks.json.
    # This MUST happen *after* all ConversableAgent instances exist and
    # *before* orchestration starts so AG2 can invoke them during send
    # and generate_reply.
    # ------------------------------------------------------------------
    try:
        from .workflow_manager import get_workflow_manager
        wm = get_workflow_manager()
        already_loaded = workflow_name in getattr(wm, '_hooks_loaded_workflows', set())
        if already_loaded:
            logger.debug(f"ü™ù [HOOKS] Skipping registration for '{workflow_name}' (already loaded)")
        registered = wm.register_hooks(workflow_name, agents, force=False)
        if registered:
            logger.info(f"ü™ù [HOOKS] Registered {len(registered)} hooks for '{workflow_name}' (already_loaded={already_loaded})")
            try:
                qualnames = [r.function_qualname for r in registered]
                logger.debug(f"ü™ù [HOOKS] Registered functions: {qualnames}")
            except Exception:
                logger.debug("ü™ù [HOOKS] Registered hooks (could not stringify qualnames)")
        else:
            logger.debug(f"ü™ù [HOOKS] No new hooks registered for '{workflow_name}' (already_loaded={already_loaded})")
    except Exception as hook_err:  # pragma: no cover
        logger.warning(f"ü™ù [HOOKS] Failed to register hooks for '{workflow_name}': {hook_err}")

    return agents

# ------------------------------------------------------------------
# RUNTIME INSPECTION UTILITIES
# ------------------------------------------------------------------

def list_agent_hooks(agent: Any) -> Dict[str, List[str]]:
    """Return a mapping of hook_type -> list of function names for a given agent.

    Supports both agent._hooks and agent.hooks structures.
    """
    out: Dict[str, List[str]] = {}
    try:
        for attr in ("_hooks", "hooks"):
            if hasattr(agent, attr):
                raw = getattr(agent, attr)
                if isinstance(raw, dict):
                    for htype, fns in raw.items():
                        names: List[str] = []
                        try:
                            for f in (fns or []):  # type: ignore
                                names.append(getattr(f, '__name__', repr(f)))
                        except Exception:
                            names.append('<error>')
                        out[htype] = names
                break
    except Exception:
        pass
    return out

def list_hooks_for_workflow(agents: Dict[str, Any]) -> Dict[str, Dict[str, List[str]]]:
    """Return hooks per agent for an agents dict."""
    return {name: list_agent_hooks(agent) for name, agent in agents.items()}

__all__ = [
    'define_agents',
    'list_agent_hooks',
    'list_hooks_for_workflow',
]