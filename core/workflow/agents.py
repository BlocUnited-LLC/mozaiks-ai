# ==============================================================================
# FILE: core/workflow/agents.py  
# DESCRIPTION: Clean agent factory following AG2 ConversableAgent patterns
# ==============================================================================
import logging
from typing import Dict, List, Callable, Any, Optional

from autogen import ConversableAgent
from .workflow_manager import workflow_manager

logger = logging.getLogger(__name__)

async def create_agents(workflow_name: str, context_variables=None, cache_seed: Optional[int] = None) -> Dict[str, ConversableAgent]:
    """
    Create ConversableAgent instances following AG2 patterns.
    
    Creates agents with proper AG2 constructor parameters:
    - name: str
    - system_message: str | list | None  
    - llm_config: LLMConfig | dict[str, Any] | Literal[False] | None
    - human_input_mode: Literal["ALWAYS", "NEVER", "TERMINATE"]
    - max_consecutive_auto_reply: int | None
    - functions: list[Callable[..., Any]] | Callable[..., Any]
    
    Args:
        workflow_name: Name of the workflow to load agents for
        context_variables: AG2 ContextVariables to pass to each agent
        cache_seed: Optional[int] = None - deterministic seed forwarded to llm_config helpers
        
    Returns:
        Dictionary of ConversableAgent instances
    """
    
    logger.info(f"üèóÔ∏è [AGENTS] Creating agents for workflow: {workflow_name}")
    from time import perf_counter
    start_time = perf_counter()

    # Load workflow configuration using file manager
    workflow_config = workflow_manager.get_config(workflow_name)
    
    if not workflow_config:
        logger.error(f"‚ùå [AGENTS] No configuration found for workflow: {workflow_name}")
        return {}
    
    agent_configs = workflow_config.get('agents', {})
    
    # Handle nested structure: agents -> agents -> agent_definitions
    if 'agents' in agent_configs:
        agent_configs = agent_configs['agents']
    
    logger.debug(f"üîß [AGENTS] Loading {len(agent_configs)} agent definitions")
    
    # ---------------------------------------------------------------
    # Load a single base LLM config; per-agent structured configs resolved by registry
    logger.debug("üîß [AGENTS] Loading base LLM config...")
    try:
        # Centralized llm_config (caching + provider aggregation)
        from .llm_config import get_llm_config as _get_base_llm_config
        extra = {"cache_seed": cache_seed} if cache_seed is not None else None
        _, base_llm_config = await _get_base_llm_config(stream=True, extra_config=extra)
    except Exception as e:
        logger.error(f"‚ùå [AGENTS] Failed to load base LLM config: {e}")
        return {}
    logger.debug("‚úÖ [AGENTS] Base LLM config loaded")
    
    # Tool function discovery via centralized loader (loads ALL tools including UI_Tools)
    try:
        from .agent_tools import load_agent_tool_functions
        agent_tool_functions = load_agent_tool_functions(workflow_name)
    except Exception as tool_load_err:
        logger.warning(f"üß© [AGENTS] Failed loading agent tool functions: {tool_load_err}")
        agent_tool_functions = {}

    agents: Dict[str, ConversableAgent] = {}

    # NOTE: UserProxyAgent is auto-generated by orchestration_patterns.py
    # based on workflow config human_in_the_loop flag. No need to create it here.
    
    # Create agents dynamically from JSON configuration
    for agent_name, agent_config in agent_configs.items():
        logger.debug(f"üîß [AGENTS] Creating agent '{agent_name}' dynamically from JSON config...")

        # Try to get structured model for this specific agent via registry
        try:
            from .structured_outputs import get_llm_for_workflow as _get_structured_llm
            extra = {"cache_seed": cache_seed} if cache_seed is not None else None
            _, llm_config = await _get_structured_llm(workflow_name, 'base', agent_name=agent_name, extra_config=extra)
            logger.debug(f"üîß [AGENTS] Got structured LLM config for {agent_name}: {llm_config}")
        except Exception as e:
            logger.debug(f"üîß [AGENTS] Failed to get structured config for {agent_name}, using base: {e}")
            llm_config = base_llm_config
            logger.debug(f"üîß [AGENTS] Using base LLM config for {agent_name}: {llm_config}")

        # Create the agent with configuration from JSON
        agent_functions = agent_tool_functions.get(agent_name, [])
        # Debug: inspect the functions we plan to attach so we can diagnose registration issues
        if agent_functions:
            func_details = []
            for i, fn in enumerate(agent_functions):
                func_details.append({
                    "index": i,
                    "repr": repr(fn),
                    "callable": callable(fn),
                    "name": getattr(fn, "__name__", None),
                    "module": getattr(fn, "__module__", None),
                })
            logger.debug(f"üß© [AGENTS] Attaching {len(agent_functions)} tool functions to {agent_name}: {func_details}")
        else:
            logger.debug(f"üß© [AGENTS] No tool functions found for {agent_name}")

        # Validate functions before passing to ConversableAgent
        for i, fn in enumerate(agent_functions):
            if not callable(fn):
                logger.error(f"üß© [AGENTS] Tool function at index {i} for agent '{agent_name}' is not callable: {fn}")
        
        # Ensure AG2 tool registration path is primed: llm_config must have a 'tools' list
        try:
            if isinstance(llm_config, dict) and 'tools' not in llm_config:
                llm_config['tools'] = []
                logger.debug(f"üß© [AGENTS] Injected empty tools list into llm_config for {agent_name} to enable AG2 function calling")
        except Exception as _inj_err:
            logger.debug(f"üß© [AGENTS] Skipped llm_config tools injection for {agent_name}: {_inj_err}")

        logger.debug(f"üîß [AGENTS] Final config for {agent_name}: config_list={llm_config.get('config_list', [])} other_keys={list(k for k in llm_config.keys() if k != 'config_list')}")
        
        # Additional debug - make a deep copy to see if something is modifying the original
        import copy
        config_copy = copy.deepcopy(llm_config)
        logger.debug(f"üîß [AGENTS] Config copy for {agent_name}: {config_copy}")
        
        # Check if config_list entries are valid IMMEDIATELY before creating agent
        config_list = llm_config.get('config_list', [])
        logger.debug(f"üîß [AGENTS] About to create agent {agent_name} with config_list length: {len(config_list)}")
        for i, entry in enumerate(config_list):
            logger.debug(f"üîß [AGENTS] FINAL CHECK Config entry [{i}] for {agent_name}: {entry}")
            if not isinstance(entry, dict):
                logger.error(f"‚ùå [AGENTS] FATAL ERROR: Config entry [{i}] is not a dict: {type(entry)} {entry}")
                raise ValueError(f"Config entry [{i}] is not a dict for agent {agent_name}")
            if not entry.get('model'):
                logger.error(f"‚ùå [AGENTS] FATAL ERROR: Config entry [{i}] missing model field: {entry}")
                raise ValueError(f"Config entry [{i}] missing model field for agent {agent_name}")

        logger.debug(f"üîß [AGENTS] Creating ConversableAgent {agent_name} with validated config...")

        # LAST CHANCE DEBUG - inspect the actual llm_config right before AG2 gets it
        logger.debug(f"üîß [AGENTS] ABSOLUTE FINAL CONFIG CHECK for {agent_name}:")
        logger.debug(f"üîß [AGENTS] llm_config type: {type(llm_config)}")
        logger.debug(f"üîß [AGENTS] llm_config keys: {list(llm_config.keys()) if isinstance(llm_config, dict) else 'NOT_DICT'}")
        if isinstance(llm_config, dict):
            logger.debug(f"üîß [AGENTS] llm_config.tools present: {'tools' in llm_config} length={len(llm_config.get('tools', [])) if isinstance(llm_config.get('tools', []), list) else 'n/a'}")

        final_config_list = llm_config.get('config_list', []) if isinstance(llm_config, dict) else []
        logger.debug(f"üîß [AGENTS] config_list length: {len(final_config_list)}")

        for idx, entry in enumerate(final_config_list):
            logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}]: {entry}")
            logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] type: {type(entry)}")
            if isinstance(entry, dict):
                logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] keys: {list(entry.keys())}")
                logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] has model: {'model' in entry}")
                logger.debug(f"üîß [AGENTS] FINAL Entry[{idx}] model value: {entry.get('model', 'MISSING')}")

        try:
            raw_human_mode = agent_config.get('human_input_mode')
            if raw_human_mode and str(raw_human_mode).upper() not in ('', 'NEVER', 'NONE'):
                logger.debug(f"[AGENTS] Ignoring configured human_input_mode {raw_human_mode} for {agent_name}; enforcing NEVER")
            human_input_mode = 'NEVER'
            agent = ConversableAgent(
                name=agent_name,
                system_message=agent_config.get('system_message', 'You are a helpful AI assistant.'),
                llm_config=llm_config,
                human_input_mode=human_input_mode,
                max_consecutive_auto_reply=agent_config.get('max_consecutive_auto_reply', 2),
                functions=agent_functions,  # AG2 functions parameter
                context_variables=context_variables,  # AG2 ContextVariables for LLM access
            )
            # After creation, log what the agent reports back (if accessible) about attached functions
            try:
                attached = getattr(agent, 'functions', None)
                if attached is None:
                    logger.debug(f"‚úÖ [AGENTS] ConversableAgent {agent_name} created (no 'functions' attribute exposed)")
                else:
                    attached_summary = [{"name": getattr(f, '__name__', None), "callable": callable(f)} for f in attached]
                    logger.debug(f"‚úÖ [AGENTS] ConversableAgent {agent_name} created with functions: {attached_summary}")
            except Exception as _ex:
                logger.debug(f"‚úÖ [AGENTS] ConversableAgent {agent_name} created but could not introspect 'functions': {_ex}")

        except Exception as e:
            logger.error(f"‚ùå [AGENTS] CRITICAL ERROR creating ConversableAgent {agent_name}: {e}")
            logger.error(f"‚ùå [AGENTS] FINAL CONFIG DUMP: {llm_config}")
            raise

        agents[agent_name] = agent

        # Minimal agent creation confirmation
        logger.debug(f"‚úÖ [AGENTS] Created '{agent_name}' with {len(agent_tool_functions.get(agent_name, []))} tools")

    # Completion log remains generic
    agent_count = len(agents)
    duration = perf_counter() - start_time
    logger.info(f"‚úÖ [AGENTS] Created {agent_count} agents for '{workflow_name}' in {duration:.2f}s")
    logger.debug(f"üîç [AGENTS] Agent names: {list(agents.keys())}")
    
    # Import and use consolidated logging for summary
    from logs.logging_config import get_workflow_session_logger
    workflow_logger = get_workflow_session_logger(workflow_name)
    
    # Log tool binding summary with proper parameters
    total_tools = sum(len(tools) for tools in agent_tool_functions.values())
    workflow_logger.log_tool_binding_summary("ALL_AGENTS", total_tools, list(agent_tool_functions.keys()))

    # NOTE: Tool registration is handled by the modular tool system
    logger.info("üîß [AGENTS] Tools registration handled by modular tool system")

    # ------------------------------------------------------------------
    # HOOK REGISTRATION
    # Register any hooks declared in workflows/<workflow>/hooks.json.
    # This MUST happen *after* all ConversableAgent instances exist and
    # *before* orchestration starts so AG2 can invoke them during send
    # and generate_reply.
    # ------------------------------------------------------------------
    try:
        from .workflow_manager import get_workflow_manager
        wm = get_workflow_manager()
        already_loaded = workflow_name in getattr(wm, '_hooks_loaded_workflows', set())
        if already_loaded:
            logger.debug(f"ü™ù [HOOKS] Skipping registration for '{workflow_name}' (already loaded)")
        registered = wm.register_hooks(workflow_name, agents, force=False)
        if registered:
            logger.info(f"ü™ù [HOOKS] Registered {len(registered)} hooks for '{workflow_name}' (already_loaded={already_loaded})")
            try:
                qualnames = [r.function_qualname for r in registered]
                logger.debug(f"ü™ù [HOOKS] Registered functions: {qualnames}")
            except Exception:
                logger.debug("ü™ù [HOOKS] Registered hooks (could not stringify qualnames)")
        else:
            logger.debug(f"ü™ù [HOOKS] No new hooks registered for '{workflow_name}' (already_loaded={already_loaded})")
    except Exception as hook_err:  # pragma: no cover
        logger.warning(f"ü™ù [HOOKS] Failed to register hooks for '{workflow_name}': {hook_err}")

    return agents

# ------------------------------------------------------------------
# RUNTIME INSPECTION UTILITIES
# ------------------------------------------------------------------

def list_agent_hooks(agent: Any) -> Dict[str, List[str]]:
    """Return a mapping of hook_type -> list of function names for a given agent.

    Supports both agent._hooks and agent.hooks structures.
    """
    out: Dict[str, List[str]] = {}
    try:
        for attr in ("_hooks", "hooks"):
            if hasattr(agent, attr):
                raw = getattr(agent, attr)
                if isinstance(raw, dict):
                    for htype, fns in raw.items():
                        names: List[str] = []
                        try:
                            for f in (fns or []):  # type: ignore
                                names.append(getattr(f, '__name__', repr(f)))
                        except Exception:
                            names.append('<error>')
                        out[htype] = names
                break
    except Exception:
        pass
    return out

def list_hooks_for_workflow(agents: Dict[str, Any]) -> Dict[str, Dict[str, List[str]]]:
    """Return hooks per agent for an agents dict."""
    return {name: list_agent_hooks(agent) for name, agent in agents.items()}

__all__ = [
    'create_agents',
    'list_agent_hooks', 
    'list_hooks_for_workflow',
]
