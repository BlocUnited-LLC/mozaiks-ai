"""Workflow-specific GitHub export wrapper for AppGenerator outputs."""

from __future__ import annotations

from typing import Any, Dict, List, Optional, Tuple

from logs.logging_config import get_workflow_logger

from workflows._shared.app_code_versions import (
    build_snapshot_document,
    build_snapshot_document_from_hashes,
    compute_patchset_document,
    extract_files_from_zip_bundle,
    get_latest_snapshot,
    get_snapshot,
    persist_patchset,
    persist_snapshot,
)
from workflows._shared.workflow_exports import get_latest_workflow_export, record_workflow_export
from workflows.AgentGenerator.tools.export_to_github import export_to_github_tool


def _get_ctx_meta(context_variables: Optional[Any]) -> Tuple[Optional[str], Dict[str, Any]]:
    chat_id = None
    meta: Dict[str, Any] = {}
    if context_variables is not None and hasattr(context_variables, "get"):
        try:
            chat_id = context_variables.get("chat_id")
            # Keep this intentionally minimal (no secrets).
            meta["app_validation_passed"] = context_variables.get("app_validation_passed")
            meta["integration_tests_passed"] = context_variables.get("integration_tests_passed")
            meta["app_validation_result"] = context_variables.get("app_validation_result")
            meta["integration_test_result"] = context_variables.get("integration_test_result")
        except Exception:
            pass
    return (str(chat_id) if chat_id else None), meta


def _repo_url_from_export(rec: Optional[Dict[str, Any]]) -> Optional[str]:
    if not isinstance(rec, dict):
        return None
    repo_url = rec.get("repo_url") or rec.get("repoUrl")
    if isinstance(repo_url, str) and repo_url.strip():
        return repo_url.strip()
    return None


def _snapshot_id_from_export(rec: Optional[Dict[str, Any]]) -> Optional[str]:
    if not isinstance(rec, dict):
        return None
    for key in ("snapshotId", "snapshot_id", "targetSnapshotId", "target_snapshot_id"):
        raw = rec.get(key)
        if isinstance(raw, str) and raw.strip():
            return raw.strip()
    return None


async def export_app_code_to_github(
    *,
    app_id: str,
    bundle_path: str,
    repo_name: Optional[str] = None,
    commit_message: Optional[str] = None,
    user_id: Optional[str] = None,
    context_variables: Optional[Any] = None,
) -> Dict[str, Any]:
    wf_logger = get_workflow_logger(workflow_name="AppGenerator", chat_id=None, app_id=app_id)
    session_id, structured_outputs = _get_ctx_meta(context_variables)

    # Fail-closed safety gate: export requires validation + integration checks to have passed.
    allow_export = True
    reasons = []
    try:
        if context_variables is not None and hasattr(context_variables, "get"):
            if context_variables.get("app_validation_passed") is not True:
                allow_export = False
                reasons.append("E2B validation has not passed.")
            if context_variables.get("integration_tests_passed") is not True:
                allow_export = False
                reasons.append("Integration checks have not passed.")
        else:
            allow_export = False
            reasons.append("Unable to confirm validation/integration status.")
    except Exception:
        allow_export = False
        reasons.append("Unable to confirm validation/integration status.")

    if not allow_export:
        error_msg = "Export blocked: " + " ".join(reasons) if reasons else "Export blocked."
        wf_logger.warning(error_msg)
        return {
            "success": False,
            "blocked": True,
            "workflow_type": "app-generator",
            "error": error_msg,
            "reasons": reasons,
            "repo_url": None,
            "job_id": None,
        }

    # Determine if this app already has an exported repo (update path -> PR).
    prior_export: Optional[Dict[str, Any]] = None
    try:
        prior_export = await get_latest_workflow_export(app_id=app_id, workflow_type="app-generator")
    except Exception:
        prior_export = None

    prior_repo_url = _repo_url_from_export(prior_export)

    # ------------------------------------------------------------------
    # UPDATE FLOW: repo exists -> compute patchset + create PR (never push)
    # ------------------------------------------------------------------
    if prior_repo_url:
        try:
            # 1) Fetch repo manifest (current base) for conflict detection + PR base.
            manifest = await export_to_github_tool.get_repo_manifest(
                app_id=app_id,
                repo_url=prior_repo_url,
                user_id=user_id,
            )
            base_commit_sha = manifest.get("baseCommitSha") or manifest.get("base_commit_sha") or manifest.get("baseCommit") or ""
            if not isinstance(base_commit_sha, str) or not base_commit_sha.strip():
                raise ValueError("Backend repo manifest missing baseCommitSha")

            repo_files: Dict[str, str] = {}
            raw_files = manifest.get("files")
            if isinstance(raw_files, list):
                for entry in raw_files:
                    if not isinstance(entry, dict):
                        continue
                    p = entry.get("path")
                    s = entry.get("sha256")
                    if isinstance(p, str) and p.strip() and isinstance(s, str) and s.strip():
                        repo_files[p.strip()] = s.strip()

            # 2) Resolve baseline snapshot (prefer last export snapshotId; fallback to repo manifest snapshot).
            base_snapshot: Optional[Dict[str, Any]] = None
            base_snapshot_id = _snapshot_id_from_export(prior_export)
            if base_snapshot_id:
                try:
                    base_snapshot = await get_snapshot(app_id=app_id, snapshot_id=base_snapshot_id)
                except Exception:
                    base_snapshot = None

            if not base_snapshot:
                # Fallback: baseline is the repo tree itself (hash-only snapshot).
                baseline_files = (
                    raw_files
                    if isinstance(raw_files, list)
                    else [{"path": p, "sha256": sha, "sizeBytes": 0} for p, sha in sorted(repo_files.items())]
                )
                base_snapshot = build_snapshot_document_from_hashes(
                    app_id=app_id,
                    session_id=session_id,
                    workflow_type="app-generator",
                    source="imported_repo",
                    files=baseline_files if isinstance(baseline_files, list) else [],
                    structured_outputs={"repo_manifest": {"repoUrl": prior_repo_url, "baseCommitSha": base_commit_sha}},
                    repo_url=prior_repo_url,
                    base_commit_sha=str(base_commit_sha).strip(),
                )
                try:
                    await persist_snapshot(snapshot_doc=base_snapshot)
                except Exception:
                    # Baseline snapshot persistence is best-effort; patchset can still be computed.
                    pass

            # 3) Create target snapshot from current bundle zip (generated output).
            bundle_files = extract_files_from_zip_bundle(bundle_path)
            target_snapshot = build_snapshot_document(
                app_id=app_id,
                session_id=session_id,
                workflow_type="app-generator",
                source="generated",
                files=bundle_files,
                structured_outputs=structured_outputs,
                repo_url=prior_repo_url,
            )
            await persist_snapshot(snapshot_doc=target_snapshot)

            # 4) Compute patchset + conflicts (baseline snapshot vs target, compared to repo HEAD).
            patchset = compute_patchset_document(
                app_id=app_id,
                base_snapshot=base_snapshot,
                target_snapshot=target_snapshot,
                repo_file_shas=repo_files,
                base_commit_sha=str(base_commit_sha).strip(),
                repo_url=prior_repo_url,
                workflow_type="app-generator",
            )
            await persist_patchset(patchset_doc=patchset)

            # 5) Request backend to create branch + PR (never push to default branch).
            patch_id = patchset.get("patchId")
            branch_name = f"mozaiks/update/{patch_id}"
            pr_title = str(commit_message or "").strip() or "Mozaiks update"
            conflicts_count = len(patchset.get("conflicts") or [])
            changes_count = len(patchset.get("changes") or [])
            pr_body = "\n".join(
                [
                    f"PatchId: {patch_id}",
                    f"AppId: {app_id}",
                    f"BaseCommitSha: {base_commit_sha}",
                    f"Changes: {changes_count}",
                    f"Conflicts: {conflicts_count}",
                    "",
                    "Notes:",
                    "- This PR was generated by MozaiksAI using file-level changes.",
                    "- Conflicts indicate repo files changed since the baseline snapshot; review carefully before merging.",
                ]
            )
            pr_res = await export_to_github_tool.create_pull_request(
                app_id=app_id,
                repo_url=prior_repo_url,
                base_commit_sha=str(base_commit_sha).strip(),
                branch_name=branch_name,
                title=pr_title,
                body=pr_body,
                changes=patchset.get("changes") if isinstance(patchset.get("changes"), list) else [],
                patch_id=str(patch_id) if patch_id else None,
                user_id=user_id,
            )
            pr_url = pr_res.get("prUrl") or pr_res.get("pr_url") or pr_res.get("url")

            # 6) Persist export metadata for chaining/visibility.
            try:
                await record_workflow_export(
                    app_id=app_id,
                    user_id=user_id,
                    workflow_type="app-generator",
                    repo_url=prior_repo_url,
                    job_id=str(pr_res.get("jobId") or pr_res.get("job_id") or "") or None,
                    meta={
                        "export_mode": "update_pr",
                        "patch_id": patch_id,
                        "base_snapshot_id": (base_snapshot or {}).get("snapshotId"),
                        "target_snapshot_id": (target_snapshot or {}).get("snapshotId"),
                        "base_commit_sha": base_commit_sha,
                        "changes_count": changes_count,
                        "conflicts_count": conflicts_count,
                    },
                    extra_fields={
                        "export_mode": "update_pr",
                        "patchId": patch_id,
                        "prUrl": pr_url,
                        "baseCommitSha": base_commit_sha,
                        "baseSnapshotId": (base_snapshot or {}).get("snapshotId"),
                        "targetSnapshotId": (target_snapshot or {}).get("snapshotId"),
                        "snapshotId": (target_snapshot or {}).get("snapshotId"),
                        "changesCount": changes_count,
                        "conflictsCount": conflicts_count,
                    },
                )
            except Exception as exc:
                wf_logger.warning(f"[EXPORT] Failed to record update PR metadata: {exc}")

            return {
                "success": True,
                "workflow_type": "app-generator",
                "export_mode": "update_pr",
                "repo_url": prior_repo_url,
                "pr_url": pr_url,
                "patch_id": patch_id,
                "base_commit_sha": base_commit_sha,
                "changes_count": changes_count,
                "conflicts_count": conflicts_count,
                "conflicts": patchset.get("conflicts"),
            }
        except Exception as exc:
            error_msg = f"Update export failed: {exc}"
            wf_logger.warning(error_msg)
            return {
                "success": False,
                "workflow_type": "app-generator",
                "export_mode": "update_pr",
                "blocked": False,
                "error": error_msg,
                "repo_url": prior_repo_url,
            }

    # ------------------------------------------------------------------
    # INITIAL EXPORT FLOW: no repo yet -> create via deploy pipeline
    # ------------------------------------------------------------------
    result = await export_to_github_tool.execute(
        app_id=app_id,
        bundle_path=bundle_path,
        repo_name=repo_name,
        commit_message=commit_message,
        user_id=user_id,
        workflow_type="app-generator",
        context_variables=context_variables,
    )

    payload = result.model_dump()
    payload["workflow_type"] = "app-generator"
    payload["export_mode"] = "initial_export"

    if result.success:
        try:
            bundle_files = extract_files_from_zip_bundle(bundle_path)
            snapshot_doc = build_snapshot_document(
                app_id=app_id,
                session_id=session_id,
                workflow_type="app-generator",
                source="generated",
                files=bundle_files,
                structured_outputs=structured_outputs,
                repo_url=result.repo_url,
                base_commit_sha=result.base_commit_sha,
            )
            snapshot_id = await persist_snapshot(snapshot_doc=snapshot_doc)
        except Exception as snap_exc:
            snapshot_id = None
            wf_logger.warning(f"[EXPORT] Failed to persist initial export snapshot: {snap_exc}")

        try:
            await record_workflow_export(
                app_id=app_id,
                user_id=user_id,
                workflow_type="app-generator",
                repo_url=result.repo_url,
                job_id=result.job_id,
                meta={"export_mode": "initial_export"},
                extra_fields={
                    "export_mode": "initial_export",
                    "snapshotId": snapshot_id,
                    "repoFullName": result.repo_full_name,
                    "baseCommitSha": result.base_commit_sha,
                    "workflowRunUrl": result.workflow_run_url,
                    "deploymentUrl": result.deployment_url,
                },
            )
        except Exception as exc:
            wf_logger.warning(f"[EXPORT] Failed to record app export metadata: {exc}")

    return payload


__all__ = ["export_app_code_to_github"]
