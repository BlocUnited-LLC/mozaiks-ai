# ==============================================================================
# FILE: Generator/Agents.py  
# DESCRIPTION: Agent factory for the Generator workflow
# ==============================================================================
import asyncio
import sys
import os
from pathlib import Path

# Add the core directory to the Python path
core_path = Path(__file__).parent.parent.parent / "core"
sys.path.insert(0, str(core_path))

from autogen import ConversableAgent
from .StructuredOutputs import get_llm
import logging

logger = logging.getLogger(__name__)

async def define_agents():
    """Define agents with unified transport channel and dynamic hooks - now driven by workflow.json"""
    
    logger.info("üèóÔ∏è [GENERATOR] Creating agents from workflow.json configuration...")
    import time
    import json
    start_time = time.time()

    # Load workflow configuration
    workflow_path = Path(__file__).parent / "workflow.json"
    with open(workflow_path, 'r', encoding='utf-8') as f:
        workflow_config = json.load(f)
    
    logger.debug(f"üîß [GENERATOR] Loaded workflow config with {len(workflow_config.get('agents', {}))} agent definitions")
    
    # Get all unique LLM config types needed
    llm_configs = {}
    agent_configs = workflow_config.get('agents', {})
    
    # Collect unique LLM config types
    unique_llm_types = set()
    for agent_name, agent_config in agent_configs.items():
        llm_type = agent_config.get('llm_config_type', 'base')
        unique_llm_types.add(llm_type)
    
    # Load all required LLM configs
    logger.debug("üîß [GENERATOR] Loading LLM configs...")
    for llm_type in unique_llm_types:
        _, llm_config = await get_llm(llm_type)
        llm_configs[llm_type] = llm_config
    logger.debug("‚úÖ [GENERATOR] LLM configs loaded (streaming handled by AG2 IOStream)")
    
    agents = {}
    
    # NOTE: UserProxyAgent is now auto-generated by groupchat_manager.py
    # based on workflow.json human_in_the_loop flag. No need to create it here.
    
    # Create agents dynamically from JSON configuration
    for agent_name, agent_config in agent_configs.items():
        logger.debug(f"üîß [GENERATOR] Creating {agent_name}...")
        
        # Get LLM config for this agent
        llm_type = agent_config.get('llm_config_type', 'base')
        llm_config = llm_configs.get(llm_type, llm_configs.get('base'))
        
        # Create the agent with configuration from JSON
        agents[agent_name] = ConversableAgent(
            name=agent_name,
            system_message=agent_config.get('system_message', ''),
            llm_config=llm_config,
            human_input_mode=agent_config.get('human_input_mode', 'NEVER'),
            max_consecutive_auto_reply=agent_config.get('max_consecutive_auto_reply', 2)
        )
    
    # Log completion
    agent_count = len(agents)
    duration = time.time() - start_time
    logger.info(f"‚úÖ [GENERATOR] Created {agent_count} agents in {duration:.2f}s")
    logger.debug(f"üîç [GENERATOR] Agent names: {list(agents.keys())}")

    # NOTE: Tool registration is now handled by the modular tool system
    # via workflow.json configuration and the WorkflowToolRegistry
    logger.info("üîß [GENERATOR] Tools will be registered via modular tool system")

    return agents